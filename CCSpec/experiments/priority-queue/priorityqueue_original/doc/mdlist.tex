\documentclass[10pt,journal,letterpaper,compsoc]{IEEEtran}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage[english]{babel}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\usepackage{enumitem}
\let\proof\relax
\let\endproof\relax 
\usepackage{amsthm}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{multicol}
\let\subcaption\relax
\usepackage[font=small]{subcaption}
\usepackage{graphicx}
\usepackage[hidelinks,bookmarks=false,pdfpagelabels]{hyperref}
\usepackage[nocompress]{cite}

%\special{papersize=8.5in,11in}
%\setlength{\pdfpageheight}{\paperheight}
%\setlength{\pdfpagewidth}{\paperwidth}

% definition environment
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{invariant}{Invariant}

% typewriter font family that support hyphenation
%\newcommand\textvtt[1]{{\normalfont\fontfamily{cmvtt}\selectfont #1}}
\hyphenation{MD-List} 
\hyphenation{skip-list}
\hyphenation{De-le-te-Min}

\algtext*{EndWhile}
\algtext*{EndFor}
\algtext*{EndIf}
\algtext*{EndFunction}
\newcommand\NIL{\text{NIL}}
\newcommand\TRUE{\text{\textbf{true}}}
\newcommand\FALSE{\text{\textbf{false}}}
\newcommand\BREAK{\text{\textbf{break}}}
\newcommand\CONTINUE{\text{\textbf{continue}}}
\newcommand\AND{\;\text{\textbf{and}}\;}
\newcommand\OR{\;\text{\textbf{or}}\;}
\algrenewcommand\algorithmicindent{1em}

\algblockdefx[StructBlock]{Struct}{EndStruct} [1]{\textbf{struct} #1} [0]{}
\algtext*{EndStruct}
\algblockdefx[ClassBlock]{Class}{EndClass} [1]{\textbf{class} #1} [0]{}
\algtext*{EndClass}
\algblockdefx[MacroBlock]{Define}{EndDefine} [2]{\textbf{define} #1(#2)} [0]{}
\algtext*{EndDefine}
\algblockdefx[InlineBlock]{Inline}{EndInline} [2]{\textbf{inline function} \textsc{#1}(#2)} [0]{}
\algtext*{EndInline}

\begin{document}

\title{A Lock-free Priority Queue Design Based on Multi-dimensional Linked Lists}
%\authorinfo{Deli Zhang\and Damian Dechev}{University of Central Florida}{de-li.zhang@knights.ucf.edu\and dechev@eecs.ucf.edu}

\author{Deli~Zhang and~Damian~Dechev%
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem The authors are with the Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, 32826. \protect\\
E-mail: de-li.zhang@knights.ucf.edu and dechev@eecs.ucf.edu}}

\IEEEtitleabstractindextext{
\begin{abstract}
    The throughput of concurrent priority queues is pivotal to multiprocessor applications such as discrete event simulation, best-first search and task scheduling. 
    Existing lock-free priority queues are mostly based on skiplists, which probabilistically create shortcuts in an ordered list for fast insertion of elements.
    The use of skiplists eliminates the need of global rebalancing in balanced search trees and ensures logarithmic sequential search time on average, but the worst-case performance is linear with respect to the input size.
    In this paper, we propose a quiescently consistent lock-free priority queue based on a multi-dimensional list that guarantees worst-case search time of $\mathcal{O}(\log N)$ for keys in the range of $[0, N)$.
    The novel multi-dimensional list (MDList) is composed of nodes that contain multiple links to child nodes arranged by their dimensionality. 
    The insertion operation works by first generating a one-to-one mapping from the scalar keys to a high-dimensional vectors space, then uniquely locating the target position by using the vector as coordinates.
    The ordering property of the MDList structure is readily maintained during insertion without rebalancing nor randomization.
    In our experimental evaluation using a micro-benchmark, our priority queue outperforms the state of the art approaches by an average of $50\%$.
\end{abstract}

%\category{D.1.3}{Concurrent Programming}{Algorithms}
%\terms{Algorithms, Performance}
\begin{IEEEkeywords}
    Concurrent Data Structure, Priority Queue, Lock-free, Multi-dimensional List, Skiplist
\end{IEEEkeywords}
}
\maketitle

\IEEEraisesectionheading{\section{Introduction}}
\IEEEPARstart{S}{calable} non-blocking priority queues are pivotal to the performance of parallel applications on current multi-core and future many-core systems.
Attempts on parallelizing search algorithms, such as best-first search~\cite{burns2010best}, do not achieve the desired performance gains due to the lack of scalable concurrent priority queues.
Priority task scheduling~\cite{wimmer2013data} and discrete event simulation applications~\cite{linden2013skiplist} also demand high-throughput priority queues to efficiently distribute workload.
A priority queues is an abstract data structure that stores a set of key-value pairs where the keys are totally ordered and interpreted as priorities. 
A priority queue is defined only by its semantics that specify two canonical operations: \textsc{Insert}, which adds a key-value pair, and \textsc{DeleteMin}, which returns the value associated with the key of highest priority and removes the pair from the queue.
In sequential execution scenarios, priority queues can be implemented on top of balanced search trees or array-based binary heaps~\cite{cormen2001introduction}. 
The latter is more efficient in practice because its compact memory footprint exploits spatial locality that optimizes cache utilization. 
For concurrent accesses by a large number of threads balanced search trees suffer from sequential bottlenecks due to required global rebalancing.
Array-based heaps suffer from heavy memory contention in the heapify operation when a newly inserted key ascends to its target location.

In recent research studies~\cite{linden2013skiplist,sundell2005fast,herlihy2006provably,fraser2007concurrent}, concurrent priority queue algorithms based on skiplists are gaining momentum.
A skiplist~\cite{pugh1990skip} is a linked list that provides a probabilistic alternative to search trees with logarithmic sequential search time on average. 
It eliminates the need of rebalancing by using several linked lists, organized into multiple levels, where each list skips a few elements. 
Links in the upper levels are created with exponentially smaller probability.
Due to the nature of randomization, skiplists still exhibit less than ideal linear worst-case search time.
Skiplist-based concurrent priority queues have a distributed memory structure that allows concurrent accesses to different parts of the data structure efficiently with low contention. 
However, \textsc{Insert} operations on skiplists involve updating shortcut links in distant nodes, which incurs unnecessary data dependencies among concurrent operations and limits the overall throughput.
Another bottleneck faced by concurrent priority queues is the inherent sequential semantics required by the \textsc{DeleteMin} operation~\cite{ellen2012inherent}.
Threads competing to remove the minimal element from the queue squander most of their effort trying to decide which one gets the minimal node.
The best existing approach employs logical deletion and batch physical deletion to alleviate the contention on head nodes~\cite{linden2013skiplist}, but the parallelism achieved by this approach is still limited because threads performing deletion have to traverse all logically deleted nodes and are forced to wait for the slow insertions.
Semantics relaxation~\cite{henzinger2013quantitative} opens up an opportunity to trade strict correctness guarantees, such as linearizability~\cite{herlihy1990linearizability}, for better overall throughput.

In this paper, we present a quiescently consistent lock-free priority queue design based on a multi-dimensional list (MDList).
The proposed multi-dimensional list stores ordered key-value pairs and guarantees worst-case sequential search time of $\mathcal{O}(\log N)$ for keys in the range of $[0,N)$.
It is composed of nodes that contain multiple links to the child nodes arranged by their dimensionality, and provides convenient concurrent accesses to different parts of the data structure.
The insertion works by first injectively mapping a scalar key into a high dimensional vector space, then uniquely locating the target position using the vector as coordinates.
Similar to a trie data structure~\cite{willard1983log}, a node in MDList shares the same coordinate prefix with all of its parent nodes, and the search is done through prefix matching rather than key comparison.
As a result, the ordering property of the data structure is readily maintained during insertion without rebalancing nor randomization.
The proposed priority queue has the following algorithmic characteristics that aim to further improve the throughput over existing approaches by exploiting a greater level of parallelism and reducing contention among concurrent operations.

\begin{itemize}
    \item Each insertion modifies at most two consecutive nodes, which allows concurrent insertions to be executed with minimal interference
    \item A \emph{deletion stack} is used to provide hints about the next minimal nodes so that \textsc{DeleteMin} operations do not need to traverse logically deleted nodes
    \item Insertions proceed optimistically without blocking overlapping deletions; they synchronize with \textsc{DeleteMin} operations only when necessary by rewinding the deletion stack
\end{itemize}

In our experimental evaluation, we compare our algorithm with Intel TBB's concurrent priority queue and the best available skiplist-based priority queues using a micro-benchmark on two hardware platforms. 
The result shows that on average our algorithm outperforms the alternative approaches by $50\%$.
%We also study the performance trade-offs between the relaxed quiescently consistent priority queue and the relaxed linearizable version.
We also show that the dimensionality of an MDList-based priority queue can be tuned to fit different application scenarios: a high-dimensional priority queue behaves more like a tree and speeds up insertions; a low-dimensional priority queue behaves more like a linked list and speeds up deletions.

The rest of the paper is organized as follows. 
In Section~\ref{sec:related}, we review and compare our approach with a number of existing concurrent priority queue algorithms.
In Section~\ref{sec:mdlist}, we define the multi-dimensional list data structure and introduce the sequential search algorithm.
We present the concurrent \textsc{Insert} and \textsc{DeleteMin} operations for our MDList-based lock-free priority queue in Section~\ref{sec:cpqueue}.
We reason about its correctness and progress properties in Section~\ref{sec:correctness}.
The performance evaluation and result analysis is given in Section~\ref{sec:experiment}.
We conclude the paper in Section~\ref{sec:conclusion}.

\section{Related Work}
\label{sec:related}
As a fundamental data structure, concurrent priority queues have been extensively studied in the literature.
Early concurrent priority queue algorithms are mostly adaptations of the sequential heap data structure.
Hunt et al.~\cite{hunt1996efficient} present a fine-grained locking approach that is built on a number of earlier heap-based algorithms.
Herlihy~\cite{herlihy1993methodology} uses an array-based binary heap as an example for the universal construction of lock-free data structures.
It requires that each thread only makes modification to a local copy of the heap and updates the pointer to the heap using atomic operations.
This serves as a fault tolerance scheme to avoid deadlocks rather than exploit fine-grained parallelism.
Both of these approaches, like all heap-based algorithms, suffer from sequential bottlenecks and increased contention due to the compact memory layout of the data structure.
We omit detailed discussion on more heap-based approaches as empirical evidence collected on modern multi-core platforms shows that they are outperformed by recent skiplist-based structures~\cite{shavit2000skiplist,sundell2005fast}.

Pugh~\cite{pugh1990concurrent} designs a concurrent skiplist with per-pointer locks, where an update to a pointer must be protected by a lock. 
Shavit~\cite{shavit1999scalable} discovers that the highly decentralized skiplist is suitable for shared-memory systems and presents a bounded priority queue based on Pugh's algorithm using fixed bins. 
However, this approach only supports a small set of fixed priorities whereas our approach supports an arbitrary range of keys.
Shavit and Lotan~\cite{shavit2000skiplist} also propose the first unbounded concurrent priority queue based on a skiplist.
Their locking approach employs logical deletion (by marking the target) that kept a specialized pointer to the current minimal item, and each \textsc{DeleteMin} operation has to traverse the lowest level list until it finds an unmarked item.
A lock-free adaptation of this algorithm was later presented by Herlihy and Shavit~\cite{herlihy2012art}.
Sundell and Tsigas~\cite{sundell2005fast} present the first linearizable lock-free priority queue based on a skiplist.
They guarantee linearizability by forcing threads to help physically remove a node before moving past it.
Herlihy et al.~\cite{herlihy2006provably} propose an optimistic concurrent skiplist that simplifies previous work and allows for easy proof of correctness while maintaining comparable performance.
Recently, Linden and Jonsson~\cite{linden2013skiplist} propose a skiplist-based lock-free priority queue that addresses the sequential bottleneck of the \textsc{DeleteMin} operation.
Their design uses a logical deletion scheme similar to Shavit and Lotan's approach described above, but provides significant performance improvement by performing physical deletions in batch. 
The drawback was that the logically deleted nodes have to always form a prefix of the lowest level list, and physical deletions cannot pass ongoing insertions.

As recognized by the above researches, the \textsc{DeleteMin} operation presents the biggest scalability challenge for concurrent priority queues.
Concurrent data structures that are strictly adherent to linearizability often pay a price for performance and scalability.
Relaxed semantics for concurrent data structures are proposed to provide considerable performance benefit when tight synchronization is not absolutely necessary~\cite{afek2010quasi,henzinger2013quantitative}.
Henzinger et al.~\cite{henzinger2013quantitative} proposed a formalization of semantics relaxation for concurrent priority queues.
Alistarh et al.~\cite{alistarh2014spraylist} present a relaxed algorithm by allowing deletion threads to randomly pick a node within a certain priority range.
Wimmer et al.~\cite{wimmer2013data} study the performance of semantically relaxed priority queues for task scheduling.
Liu and Spear~\cite{liu2012mounds} proposed a concurrent priority queue based on a hybrid data structure called the mound.
Their approach consists of a rooted tree of sorted linked lists, which supports simultaneously extract multiple elements from the head of the queue.
However, their lock-free implementation requires double-word CompareAndSwap, and relies on randomization to balance the length of each sub-lists.
While the above approaches study the trade-offs of semantic relaxation, this paper tries to exploit the performance benefit of relaxing the consistency criteria.

The proposed MDList also bears some similarity to trie data structures~\cite{fredkin1960trie,willard1983log} in that the keys are ordered by their prefixes: a node always shares the same key prefix with its parent nodes.
Lock-free trie designs such as the concurrent tries~\cite{prokopec2012concurrent} and the skiptrie~\cite{oshman2013skiptrie} provides log-logarithm search time, but their algorithm cannot be readily transfered to a priority queue implementation.
To the best of our knowledge, there is no lock-free implementation of priority queue based on a regular trie data structure. 
One difficulty is that the minimal item in a trie is stored in a leaf node, so retrieving the minimal item has to be done through repetitive search.
Designing linearizable \textsc{DeleteMin} is also challenging in a trie, because new minimal items can be concurrently inserted at higher level while the \textsc{DeleteMin} operation proceeds to lower levels.
MDList, on the other hand, behaves like a heap where the root node always holds the item with the smallest key.

%TODO: performance trade-off related, include it only when page limit allows
%Fraser and Harris outline the design of three concurrent skip lists using CAS, MCAS, and FSTM~\cite{fraser2007concurrent}.
%They illustrate the trade-off between simplicity and efficiency among these implementations: CAS-base skip lists provides superior performance over the other two, and the FSTM-based approach is straightforward to implement; MCAS-based approach reaches for the middle ground between the former two methods.


\section{Multi-dimensional List}
\label{sec:mdlist}
The core idea of a multi-dimensional list is to partition a linked list into shorter lists and rearrange them in a multi-dimensional space to facilitate search.
Just like a point in a $D$-dimensional space, a node in a $D$-dimensional list can be located by a $D$-dimensional coordinate vector.
The search operation examines one coordinate at a time and locates correspondent partitions by traversing nodes that belong to each dimension. 
The search time is bounded by the dimensionality of the data structure and logarithmic search time is achieved by choosing $D$ to be a logarithm of the key range. 
%We limit our discussion on three operations search, insertion and deletion which is needed by priority queues, but it is possible to support other operations as well.

\subsection{From Linked List to 2DList}
\label{sec:mdlist-overview}
An ordered linked list keeps its nodes sorted linearly as if they were attached to a one-dimensional line.
To find an existing node or insert a new node, one starts from the head and examines each node consecutively.
Given a list of nodes, the search operation takes linear time to complete on average.
The linked list illustrated in Fig.~\ref{fig:mdlist1d} has 16 nodes partitioned into 4 columns. 
This arrangement reveals a property concealed by the typical one-dimensional representation: the nodes are sorted along the columns as well as across the rows, and each column contains a unique range of nodes that have greater keys than the nodes in the previous column.
Because a column is substantially shorter than the entire list, we can locate a node much faster if we firstly determine which column the node belongs to and then search for it within the column. 
However, a one-dimensional linked list lacks two essential properties required by the above search scheme: 1) short-cut links among columns which allow the search operation to switch from one column to another; 2) a function that maps keys into key ranges covered by each column.

\begin{figure}[h]
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./graph/mdlist-1d}
        \caption{Linked List}
        \label{fig:mdlist1d}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./graph/mdlist-2d}
        \caption{2D List}
        \label{fig:mdlist2d}
    \end{subfigure}
    \caption{From linked list to 2DList}
    \label{fig:mdlist}
\end{figure}

We show an example construction of a 2DList that satisfies these requirements in Fig.~\ref{fig:mdlist2d}.
We replace the pointers linking the bottom nodes to the top nodes in Fig.~\ref{fig:mdlist1d} by links among the top nodes so that the top elements of each column form a one-dimensional linked list.
This essentially converts the linked list into a tree, but we find it more convenient to visualize it as a multi-dimensional list when discussing the algorithms in the following sections.
We also compute a 2-dimensional vector $\mathbf{k}=(k_0,k_1)$ based on the integer key of each node, which serves as the node's unique coordinate in the 2-dimensional space.
The mapping from a key to its coordinate is one-to-one, and we will discuss this in more detail in Section~\ref{sec:coord}.
The nodes are arranged such that the top nodes of each column are ordered by $k_0$, while every node in one column shares the same $k_0$ and is ordered by $k_1$.
We call the top nodes \emph{dimension 0 nodes} (because they are ordered by the 0th element in the coordinate vector), and the nodes in each column \emph{dimension 1 nodes}.
To search for a node, for example node $(2,3)$, we begin by traversing the dimension 0 nodes as if we were traversing a one-dimension linked list.
The only difference is that instead of examining the actual key we examine the $k_0$ of each node and compare it against the target's $k_0$.
We stop at node $(2,0)$, and continue to traverse the third column, which consists of dimension 1 nodes. 
We look for the node with $k_1 = 3$ and eventually locate node $(2,3)$.
The average and worst-case search times are reduced to a square root of the original times, and we can further improve them by extending the 2DList into higher dimensions.

\theoremstyle{definition}
\subsection{Definition}
We generalize the construction of the 2-dimensional list to a list of arbitrary dimensions and give the following definition of our multi-dimensional list.
\begin{definition}
\label{def:mdlist}
    A $D$-dimensional list is a rooted tree in which each node is implicitly assigned a dimension of $d \in [0,D)$. The root node's dimension is $0$. A node of dimension $d$ has no more than $D-d$ children, where the $m$th child is assigned a dimension of $d'=d+m-1$. 
\end{definition}

In an ordered multi-dimensional list, we associate every node with a coordinate vector $\mathbf{k}$, and sort the dimension $d$ nodes according to $k_d$ as depicted in Fig.~\ref{fig:mdlist2d}.
The following requirement prescribes the exact arrangement of nodes according to their coordinates.
%and should be satisfied at all times.

\theoremstyle{definition}
\begin{definition}
\label{def:mdlistsort}
    Given a non-root node of dimension $d$ with coordinate $\mathbf{k}=(k_0,...,k_{D-1})$ and its parent with coordinate $\mathbf{k'}=(k'_0,...,k'_{D-1})$ in an ordered $D$-dimensional list: $k_i = k'_i, \;\forall \;i \in [0, d) \land k_d > k'_d$.
\end{definition}

A fundamental property is that a high-dimensional list can be decomposed into a number of low-dimensional lists: every dimension 0 node in a $D$-dimensional list can be seen as the root node of a $(D-1)$-dimensional list.
For example, the 2DList in Fig.~\ref{fig:mdlist2d} consists of four 1DLists.
This is analogous to the process of slicing a cube into planes and a plane into lines.
If we repeat the decomposition process recursively, we obtain multi-dimensional lists with fewer and fewer dimensions and eventually we arrive at a single node.
The design of the search algorithm, described in more details in Section~\ref{sec:search}, is based on this decomposability property.

%\begin{theorem}
%\label{def:mdlistsublist}
%In an ordered $D$-dimensional list, all nodes that share the same coordinate prefix (the sequence of coordinates starting from the first coordinate) form an ordered $(D-i)$-dimensional list, where $i$ is the length of the prefix.
%\end{theorem}

%\begin{proof}
    %Let $S$ be the set of nodes that share the coordinate prefix $\mathbf{p}$, $l$ be the $(D-d)$-dimensional list formed by $S$, and $n \in S$ be the root node of $l$. Assume there exists a node $n' \in S$ and $n' \notin l$.
    %with coordinate $\mathbf{k'}$ where $(k'_0,...,k'_d) = \mathbf{p}$.  
%\end{proof}


\subsection{Structures}
Following Definition~\ref{def:mdlist}, it is straightforward to define the structures of a sequential MDList.
In Algorithm~\ref{alg:structure}, we define the dimension of an MDList as a constant integer $D$ and the range of the keys as $N$.
The class of MDList itself also contains a pointer to the head (root) node.
The functions presented in the following sections are member functions of the MDList class unless otherwise specified, so they have access to the class fields by default.
A node in MDList contains a key-value pair, an array $k[D]$ of integers as the coordinate vector, and an array of child pointers in which the $d$th pointer links to a dimension $d$ child node.
Since nodes of high dimensions have less children than nodes of low dimensions, for a $d$ dimension node it is possible to allocate a child array that fits only $d$ pointers to reduce memory consumption. 
However, for simplicity, we choose to allocate child arrays of size $D$ where $D$ is the dimension of the MDList for all nodes. 
For a dimension $d$ node, only the indices $d$ through $D-1$ of its child array are valid while the rest are unused.
We do not need to store the dimension of a node in the node, it is implicitly deduced by the search algorithm based on the index of the node's pointer in its parent's child array.
\begin{algorithm}[ht]
    \caption{MDList Structures}
    \label{alg:structure}
    \vspace{-0.1in}
    \begin{multicols}{2}
        \begin{algorithmic}[1]
            \Class{MDList}
            \State \textbf{const int} $D$
            \State \textbf{const int} $N$
            \State \textbf{Node*} $head$
            \EndClass
            \Struct{Node}
            \State \textbf{int} $key,\;k[D]$
            \State \textbf{void*} $val$
            \State \textbf{Node*} $child[D]$
            \EndStruct
        \end{algorithmic}
    \end{multicols}
    \vspace{-0.1in}
\end{algorithm}

MDList is more memory efficient than tries and skiplists.
A regular trie is a d-ary tree with internal nodes and leaf nodes. 
Values are stored in leaf nodes so pointers to internal nodes consumes extra memory.
In a skiplist, upper level links are redundant pointers, i.e. a node may have multiple inbound pointers.
In contrast, an MDList is a not a d-ary tree and every node stores a value.
Since each node in MDList has exactly one inbound pointer, the memory requirement for MDList is linear with respect to the input size.


\subsection{Vector Coordinates}
\label{sec:coord}
There are two requirements for the function that maps a scalar key into a high dimensional vector: 1) it is injective or one-to-one, i.e. distinctness among the keys are preserved; 2) it is monotonic, i.e. the original order among the scalar keys are preserved in the vector space (vector ordering are decided by Definition~\ref{def:mdlistsort}).
Additionally, it would be beneficial if the vector coordinates are uniformly distributed in the vector space so that each dimension of the MDList holds comparable number of nodes. 
Uniform distribution minimizes the number of nodes in each dimension and consequently optimize the search time.
There are infinitely many functions that meet the above requirements.
In Algorithm~\ref{alg:mapping}, we present a simple method that uniformly maps a range of integer keys into a vector space.

\begin{algorithm}[ht]
    \caption{Mapping from integer to vector}
    \label{alg:mapping}
    \begin{algorithmic}[1]
        \Function{KeyToCoord}{$\textbf{int}\;key$}
        \State \textbf{int} $basis \gets \lceil\sqrt[D]{N}\:\rceil,\;quotient\gets key,\;k[D]$
        %\State $basis \gets \lceil\sqrt[D]{N}\:\rceil$
        %\State $quotient \gets key$
        \For {$i \in (D, 0]$}
        \State $k[i] \gets quotient \mod basis$
        \State $quotient \gets \lfloor quotient \div basis \rfloor$
        \EndFor
        \State \Return k
        \EndFunction
    \end{algorithmic}
\end{algorithm}
We first compute the maximum number of nodes in each dimension based on the range of the keys $N$. 
In practice, the range of keys is usually known prior to the execution either explicitly through the specification of the user application or implicitly through the key's data type.
For example, if the keys are 32-bit integers and we choose the dimension of MDList to be 8, then in each dimension there are at most 16 (8th root of $2^{32}$) keys. 
We can then obtain the coordinate vector by converting the base of the original key. 
In the above case, each digit in the 16-based number corresponds to a coordinate in an 8-dimension vector.
Given a key of 1000, its 16-based representation is \texttt{0x3E8} and the coordinates would be (0,0,0,0,0,3,E,8).
In general, to uniformly distribute keys within range $[0,N)$ in a D-dimension space, the maximum number of keys in each dimension is $b=\lceil\sqrt[D]{N}\rceil$. 
The mapping from an integer key to its vector coordinates is essentially converting it to an $b$-based number and using each digit as the correspond value in the D-dimension vector.

We focus on unique integer keys in this paper, but duplicate keys can be handled by reserving a few bits to achieve uniqueness as detailed in previous work~\cite{fraser2007concurrent,sundell2005fast}.
If other types of keys such as strings are needed, one needs to devise a custom mapping or simply convert the keys into integers and use the above mapping.
Since the dimension of an MDList $D$ affects the memory layout and the computation of vector coordinates, it must be decided before the execution of the program.
We provide detailed discussion on the performance impact of different dimensionality in Section~\ref{sec:experiment}. 
%It is possible to dynamically change the dimension of an MDList filled with elements. To do this, one must keep a consistent ordering between vector coordinates of different length. 

\subsection{Search}
\label{sec:search}
\begin{algorithm}[ht]
    \caption{Search for a node with coordinates $\mathbf{k}$}
    \label{alg:search}
    \begin{algorithmic}[1]
        \Function{Search}{$\textbf{int[]}\;k$} 
        \State $\textbf{Node*},\;curr \gets head,\;\textbf{int}\;d \gets 0$
        %\State $curr \gets head,\:d \gets 0$
        \While {$d < D$} \label{l:searchend}
        \While {$curr\neq\NIL \AND k[d] > curr.k[d]$} \label{l:overshoot}
        \State $curr \gets curr.child[d]$
        \EndWhile
        \If {$curr=\NIL \OR k[d] < curr.k[d]$} \Return \NIL \label{l:checknexdim}
        \Else $\;d \gets d+1$ \label{l:advance}
        \EndIf
        \EndWhile
        \State \Return $curr$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

We outlined the search process for a simple 2DList in Section~\ref{sec:mdlist-overview}.
Following the same methodology, we present the search algorithm for a D-dimensional list in Algorithm~\ref{alg:search}.
The \textsc{Search} function returns the node containing the coordinates $\mathbf{k}$ if it exists.  
Given a $D$-dimensional list, we search for an element by traversing the dimension $d$ nodes that do not overshoot the node containing the coordinates being searched for (line~\algref{alg:search}{l:overshoot})\footnote{Throughout the paper, we use $a.b$ to denote line $b$ in algorithm $a$}.
When it is not possible to make further progress at the current dimension, the search advances to the next dimension (line~\algref{alg:search}{l:advance}).
According to the condition on line~\algref{alg:search}{l:overshoot} and~\algref{alg:search}{l:checknexdim}, the search only increases the dimension if $curr$ node exists and $k[d]=curr.k[d]$, which guarantees that those pivot nodes always share the same coordinate prefix as the node being searched for.
The outer while loop terminates when the search has visited all of the nodes in the highest dimension (line~\algref{alg:search}{l:searchend}).
If so, $curr$ must be immediately in front of the node that contains the desired coordinates , i.e. the search must have exhaustively compared every coordinate of $curr$ with $\mathbf{k}$ and they match.
Otherwise, the search failed to proceed to the highest dimension (early termination on line~\algref{alg:search}{l:checknexdim}), and the target node is not in the list.
Fig.~\ref{fig:mdlist3dsearch} illustrates a 3DList with up to four nodes in each dimension.
To search a node, say $(3,3,2)$.
The traverse begins at the root node and proceeds through all dimension 0 nodes.
It then increases the search dimension $d$ and continues to traverse the 2DList rooted at $(3,0,0)$.
The search further increases dimension and continues to traverse the 1DList rooted at $(3,3,0)$ before reaching the target node.
\begin{figure*}[t]
    \begin{subfigure}{0.47\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./graph/mdlist-3d}
        \caption{Search for $(3,3,2)$}
        \label{fig:mdlist3dsearch}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.52\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./graph/mdlist-3d-ins}
        \caption{Insert New Node}
        \label{fig:mdlist3dins}
    \end{subfigure}
    \caption{\textsc{Insert} operation in a 3DList}
    \label{fig:mdlist3d}
\end{figure*}

It is straightforward to deduce that the worst-case time complexity of the search algorithm is $\mathcal{O}(D \cdot M)$ where $M$ is the maximum number of nodes in one dimension.
For keys within the range of $[0,N)$, if we uniformly map them into the $D$-dimensional space using Algorithm~\ref{alg:mapping}, $M$ is bounded by $\sqrt[D]{N}$.
    This gives $\mathcal{O}(D \cdot \sqrt[D]{N})$, which is equivalent to $\mathcal{O}(\log{N})$, if we choose $D \propto \log{N}$ (Note that $\sqrt[\log{N}]{N}=2$).
This serves as a guideline for choosing $D$ in sequential scenarios. 
For example, a 32DList that holds 2 nodes in each dimension provides comparable performance to that of balanced search trees with 32-bit integer keys.
As the capacity of MDList grows exponentially with respect to its dimensionality, MDList of higher dimensions can accommodate an even wider range of keys.  
%Search time is not related to the completeness of MDList, but length of each dimension

\subsection{Insertion and Deletion}
\label{sec:mdlistinsdel}
A unique property of MDList, which makes it suitable for concurrent accesses, is the locality of its insertion and deletion: each operation requires updating at most two consecutive nodes in the data structure. 
For brevity, we outline the sequential insertion and deletion in this section. 
The pseudo code is presented in Section~\ref{sec:cpqueue} when we explain in detail the concurrent versions of the algorithms.

% TODO: maybe change child to children?
The insertion operation involves two steps: node splicing and child adoption.
In the first step, we search and splice as depicted by the dashed green arrows in Figure~\ref{fig:mdlist3d}.
The appropriate insert position of the new node is determined by using a modified version of the \textsc{Search} algorithm, which keeps a record of the predecessor and the dimension of the new node (the index of the new node in its predecessor's child array).
Splicing involves pointing to the old child of the predecessor from the new node and updating the child pointer of the predecessor.
In Figure~\ref{fig:mdlist3dins}, we insert a new node $(2,0,0)$ between its predecessor $(1,0,2)$ and the predecessor's old child $(2,0,1)$.
The new node becomes a dimension 0 child of its predecessor and the old child becomes a dimension 2 child of the new node.
The second step is needed when the dimension of the old child has been changed due to the insertion of a new node.
This extra child adoption process ensures that the nodes which are no longer accessible through the old child can be reached through the new node.
According to Definition~\ref{def:mdlist} the dimension of a node's children should be no less than the dimension of the node itself.
If the dimension of a node increases from $d$ to $d'$, its children within the range of $[d,d')$ must be adopted.
As marked by the dotted red arrows in Figure~\ref{fig:mdlist3d}, the new node takes over two children $(3,0,0)$ and $(2,1,0)$ from the old child $(2,0,1)$, the dimension of which increased from 0 to 2. 

The deletion operation is performed in a similar way: the child ($n_c$) with the highest dimension of the node being deleted ($n$) is linked to its parent; next, $n$ transfers its children to $n_c$, if the dimension of $n_c$ is changed.


\section{Lock-free Priority Queue}
\label{sec:cpqueue}
The proposed MDList provides convenient support for concurrent \textsc{Insert} operations because of its decentralized structure.
As mentioned in Section~\ref{sec:mdlistinsdel}, each insertion takes one or two steps and updates no more than two consecutive nodes.
We guarantee lock-free progress in the node splicing step by employing the techniques used by Harris's linked list algorithm~\cite{harris2001pragmatic}. 
Lock-freedom ensures system wide progress while allowing individual threads to starve~\cite{herlihy2012art}.
To provide for lock-free progress in the child adoption step, we need to announce the operation globally. 
This allows the interrupting threads help finish the operation in case the insertion thread is preempted.

\setlength{\columnsep}{8pt}
\begin{algorithm}[ht]
    \caption{Priority Queue Structures}
    \label{alg:pqstructure}
    \vspace{-0.1in}
    \begin{multicols}{2}
        \begin{algorithmic}[1]
            \Class{PriorityQueue}
            \State \textbf{const int} $D,N,R$
            \State \textbf{Node*} $head$
            \State \textbf{Stack*} $stack$
            \State \textbf{PurgeDesc*} $pdesc$
            \EndClass
            \Statex
            \Struct{Node}
            \State \textbf{int} $key, k[D], seq$
            \State \textbf{void*} $val$
            \State \textbf{Node*} $child[D], prg$
            \State \textbf{AdoptDesc*} $adesc$
            \EndStruct
            \Struct{AdoptDesc}
            \State \textbf{Node*} $curr$
            \State \textbf{int} $dp,dc$ 
            \EndStruct
            \Statex
            \Struct{PurgeDesc}
            \State \textbf{Node*} $head,\;prg$
            \EndStruct
            \Statex
            \Struct{Stack}
            \State \textbf{Node*} $head, node[D]$
            \EndStruct
            \Statex
        \end{algorithmic}
    \end{multicols}
    \vspace{-0.1in}
\end{algorithm}


\begin{algorithm}[ht]
    \caption{Pointer Marking}
    \label{alg:pointermarking}
    \begin{algorithmic}[1]
        \State \textbf{const int} $F_{adp} \gets \texttt{0x1},\;F_{prg} \gets \texttt{0x2},\;F_{del} \gets \texttt{0x1}$
        \Define{SetMark}{$p,\;m$} $(p\;|\;m)$
        \EndDefine
        \Define{ClearMark}{$p,\;m$} $(p\;\&\;\sim m)$
        \EndDefine
        \Define{IsMarked}{$p,\;m$} $(p\;\&\;m)$
        \EndDefine
    \end{algorithmic}
\end{algorithm}

The delete method described in Section~\ref{sec:mdlistinsdel} poses a scalability challenge for concurrent \textsc{DeleteMin} operations because constant child adoption incurs heavy contention on the head node. 
To avoid such performance penalties, we introduce several improvements to the existing logical deletion techniques. 
Namely, we use a \emph{deletion stack} that hints the search operation about the next minimal node. 
This prevents deletion operations from repeatedly traversing logically deleted nodes as is observed in~\cite{linden2013skiplist,shavit2000skiplist}.
We also design a stack rewind mechanism that allows insertions to proceed optimistically without requiring logically deleted nodes to form a prefix, as is the case in~\cite{linden2013skiplist}. 
As a result, our approach presents a relaxation to the \textsc{DeleteMin} semantics in order to trade for overall throughput. 
%This helps reduce the number of child adoptions and increases throughput.


We define the structure of the concurrent priority queue in Algorithm~\ref{alg:pqstructure}, which also contains definitions for the deletion stack and the descriptor objects.
A descriptor object~\cite{herlihy2012art} is a data structure that stores operation context and guides helping threads to finish the operation.
%Compared to the MDList class, the \textsc{PriorityQueue} class needs extra fields to store the deletion stack and a purge descriptor as described below. Three new fields, $seq$, $purged$, and $adesc$, are added to the \textsc{Node} structure.
The priority queue is initialized with a dummy head node, which has the minimal key 0.
The node array in the deletion stack is initially filled with the dummy head.
We employ the pointer marking technique described by Harris~\cite{harris2001pragmatic} to mark adopted child nodes as well as logically deleted nodes. 
The macros for pointer marking are defined in Algorithm~\ref{alg:pointermarking}.
$F_{adp}$ and $F_{prg}$ flags are co-located with the $child$ pointers while $F_{del}$ flag is co-located with the $prg$ field.

\subsection{Concurrent Insert}
\label{sec:cpqueueins}
We list the concurrent \textsc{Insert} function in Algorithm~\ref{alg:insert}.
The insertion operation locates the target position and updates the child pointer of the predecessor node.
The search begins from the head of the queue (line~\algref{alg:insert}{l:insfromhead}).
Given a new node, \textsc{LocatePred}\footnote{We use \textbf{inline} functions so that they have access to the caller's local variables without implicit argument passing.} tries to determine its immediate parent $pred$ and child $curr$ (line~\algref{alg:insert}{l:locpre1} and~\algref{alg:insert}{l:locpre2}).
It also keeps the dimension of the node being inserted in $dp$ and the dimension of the child in $dc$ (line~\algref{alg:insert}{l:dp} and~\algref{alg:insert}{l:dc}).
The new node should be inserted as the dimension $dp$ child of the $pred$ node, while a non-empty $curr$ node will become the dimension $dc$ child of the new node.
The deletion stack $s$ is also updated during the search (the usage of $s$ will be detailed in the next two sections).
The conditional check on line~\algref{alg:insert}{l:dupnode} is true when a node with the same coordinates already exists, thus the insertion terminates.
If the progress of the insertion is delayed, it helps finish any pending child adoption tasks on nearby nodes.
The code between lines~\algref{alg:insert}{l:beginhelp} and~\algref{alg:insert}{l:endhelp} reads the $adesc$ fields from $pred$ and $curr$ and tests if helping is needed.
Since a child adoption process updates the children indexed from $dp$ to $dc$, the insertion must help $pred$ node if it intends to insert the new node into this range.
Likewise, the insertion does not need to help $curr$ node if it is not going to adopt children from $curr$ node.
Prior to atomically updating the link to the new node, we fill the remaining fields of the new node (line~\algref{alg:insert}{l:beginfill} and~\algref{alg:insert}{l:endfill}).
If the new node needs to adopt children from $curr$ node, we use an adopt descriptor to store the necessary context (line~\algref{alg:insert}{l:filldesc}).
The pointers within the range $[0, dp)$\footnote{We use indexing notion $[a:b]$ to address elements within the range of $[a, b)$.} of the new node's child array are marked with $F_{adp}$.
This effectively invalidates these positions for future insertions.
The pointers within the range $[dp, D]$ are set to \textsc{NIL} meaning they are available for attaching child nodes.
On line~\algref{alg:insert}{l:link}, the standard \textsc{CompareAndSwap} (CAS) atomic synchronization primitive is used to update the $pred$ node's child pointer.
The CAS would fail under three circumstances: 1) the desired child slot has been updated by another competing insertion; 2) the desired child slot has been invalidated by a child adoption process; and 3) the desired child slot has been invalidated by a purge process.
If any of the above cases is true, the loop restarts.
Otherwise, the insertion proceeds to finish its own child adoption process and rewind the deletion stack.
The deletion stack needs to be rewound if the new node was inserted into a position that cannot be reached by future \textsc{DeleteMin} operations.
We explain this synchronization mechanism in details in Section~\ref{sec:cpqueuerewind}.
\begin{algorithm}[t]
    \caption{Concurrent Insert}
    \label{alg:insert}
    \begin{algorithmic}[1]
        \Function{Insert}{$\textbf{int}\;key,\;\textbf{void*}\;val$}
        \State \textbf{Node*} $node$ 
        \Comment the new node
        \State \textbf{Node*} $pred,\;curr$ 
        \Comment new node's parent and child
        \State \textbf{int} $dp,\;dc$ 
        \Comment dimension of node in pred and curr 
        \State \textbf{AdoptDesc*} $ad$
        \Comment descriptor for child adoption task
        \State \textbf{Stack*} $s$
        \Comment stack of search path for the insertion
        \State \textbf{PurgeDesc*} $pd$
        \Comment descriptor for purge operation
        \State $node \gets \text{\textbf{new Node}}$
        \State $node.key \gets key,\;node.val \gets val$
        \State $node.k[0:D] \gets \text{\textsc{KeyToCoord}}(key)[0:D]$
        \State $node.child[0:D] \gets \NIL$
        \While{\TRUE}
        \State $pd \gets pdesc$
        \If {$pd \neq \NIL$} \Call{FinishPurging}{$pd$}
        \EndIf
        \State $pred \gets \NIL,\;curr \gets head,\;dp \gets 0,\;dc \gets 0$ \label{l:insfromhead}
        \State $s \gets \textbf{new Stack},\;s.head \gets curr$ \label{l:recordhead}
        \State \Call{LocatePred}{ } \label{l:locpre1}
        \If{$dc=D$} \label{l:dupnode}
        %TODO: cannot quit yet, check deletion and re-enable node if needed. We can keep it like this if input keys are unique
        \BREAK
        \EndIf
        \State $ad \gets pred.adesc$ \label{l:beginhelp}
        \If{$ad \neq \NIL \AND dp \in [ad.dp,\;ad.dc]$}
        \State \Call{FinishInserting}{$pred,\;ad$}
        \State \CONTINUE
        \EndIf
        \State $ad \gets curr\ne\NIL\;?\;curr.adesc\;:\;\NIL$
        \If{$ad \ne \NIL \AND dp \ne dc$}
        \State \Call{FinishInserting}{$curr,\;ad$} \label{l:endhelp}
        \EndIf
        \State $ad \gets \NIL$ \label{l:beginfill}
        \If {$dp \ne dc$}
        \State $ad \gets \text{\textbf{new AdoptDesc}}$
        \State $ad.curr \gets curr,\;ad.dp \gets dp,\;ad.dc \gets dc$ \label{l:filldesc}
        \EndIf
        \State $node.child[0:dp] \gets F_{adp}$ \label{l:initadp}
        \State $node.child[dp:D] \gets \NIL$ 
        \State $node.child[dc] \gets curr,\;node.adesc \gets ad$ \label{l:endfill} 
        \If {$\text{\textsc{CAS}}(\&pred.child[dp],\;curr,\;node)$} \label{l:link}
        \If {$ad \ne \NIL$}
        \State \Call{FinishInserting}{$node,\;ad$}
        \EndIf
        \State \Call{RewindStack}{ } \label{l:rewind}
        \State \BREAK
        \EndIf
        \EndWhile
        \EndFunction
        \Statex
        \Inline{LocatePred}{ } \label{l:locpre2}
        \While {$dc < D$}
        \While {$curr\neq\NIL \AND node.k[dc] > curr.k[dc]$} \label{l:predcheck1}
        \State $pred \gets curr,\:dp \gets dc$ \label{l:dp}
        \State $curr \gets curr.child[dc]$
        \EndWhile
        \If {$curr=\NIL \OR node.k[dc] < curr.k[dc]$} \label{l:predcheck2}
        \State \BREAK
        \Else
        \State $s.node[dc] \gets curr,\;dc \gets dc+1$ \label{l:dc}
        \EndIf
        \EndWhile
        \EndInline
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
    \caption{Child Adoption}
    \label{alg:adoption}
    \begin{algorithmic}[1]
        \Function{FinishInserting}{$\textbf{Node*}\:n,\;\textbf{AdoptDesc*}\:ad$}
        \State \textbf{Node*} $child,\;curr \gets ad.curr$ 
        \State \textbf{int} $dp \gets ad.dp,\;dc \gets ad.dc$
        \For {$i \in [dp, dc)$} \label{l:adoptionfor}
        \While {$!\textsc{IsMarked}(child,F_{adp}) \AND !\textsc{CAS}(\&curr.child[i],\linebreak\;child,\;\textsc{SetMark}(child,\;F_{adp})$} \label{l:setadp} \label{l:adoptionwhile}
        \State $child \gets curr.child[i]$
        \EndWhile
        \State $child \gets \textsc{ClearMark}(child,\;F_{adp})$
        %\If{$n.child[i] = \NIL$} \label{l:checkadopt}
        \State $\text{\textsc{CAS}}(\&n.child[i],\;\NIL,\;child)$ \label{l:adopt}
        %\EndIf
        \EndFor
        \State $\text{\textsc{CAS}}(\&n.adesc,\;ad,\;\NIL)$
        \EndFunction
    \end{algorithmic}
\end{algorithm}


The \textsc{FinishiInserting} function in Algorithm~\ref{alg:adoption} performs child adoption on a given node $n$ with the descriptor $ad$.
This is a helping procedure that must correctly handle duplicate and simultaneous executions.
The function first reads the adoption context from the descriptor into its local variables.
It then transfers $curr$ node's children within the range of $[dp, dc)$ to $n$.
Before a child pointer can be copied, we must safeguard it so that it cannot be changed while the copy is in progress.
This is done by setting the $F_{adp}$ flag in the child pointers (line~\algref{alg:adoption}{l:adoptionwhile}).
Once the flag is set either by this thread through a successful CAS operation or by other threads, the function proceeds to copy the pointer to $n$ (line~\algref{alg:adoption}{l:adopt}). 
%This latter is done only if the corresponding child of $n$ equals \textsc{NIL} (line~\algref{alg:adoption}{l:checkadopt}). 
Finally, the descriptor field in $n$ is cleared to designate the operation's completion.


%The node is always inserted into the sub-MDList with largest possible dimension, and can only be pushed down into lower dimension sub-MDList.
%Insert at earliest possible position, dimension only increases
%conflict with deleteion which prompts dimension

\subsection{Concurrent DeleteMin}
\label{sec:cpqueuedel}
Logical deletion speeds up \textsc{DeleteMin} operation by performing physically deletion in batch or at a later stage when the memory accesses are less congested.
One limitation with previous logical deletion approaches is that they need to traverse all logically deleted nodes before reaching the first unmarked node .
This proves to be troublesome especially for an MDList-based priority queue. 
Since an MDList is a rooted tree, reaching the minimal node is done by a traversing procedure similar to a depth first search.
As the search extends to higher dimensions, it traverses exponentially more nodes, which slows down logical deletion.
Additionally, a naive implementation of the search algorithm based on recursion may lead to poor performance because of the overhead of function calls.  
We design an iteration-based \textsc{DeleteMin} algorithm by using a \emph{deletion stack}.
The deletion stack, as defined in Algorithm~\ref{alg:pqstructure} is an array of $D$ node pointers with an extra head pointer.
The node at index $d$ corresponds to a $d$-dimensional node in the MDList, and all nodes in the array form a path through which the target node can be reached.
The functionality of a deletion stack is similar to a regular LIFO stack employed by a depth-first search algorithm.
The difference is that elements in a deletion stack can also be accessed by index, which allows for efficient stack update when the \textsc{DeleteMin} algorithm skips several logically deleted nodes. 
The advantage of employing the deletion stack is twofold: 1) it reduces node traversal by providing hints about the position of the next minimal node; 2) it converts the typically recursion-based search algorithm into an iteration-based one.
\begin{algorithm}[t]
    \caption{Concurrent DeleteMin}
    \label{alg:deletemin}
    \begin{algorithmic}[1]
        \Function{DeleteMin}{ }
        \State \textbf{Node*} $min,\;prg,\;last,\;child$ 
        %\Comment min node, purged node 
        \State \textbf{AdoptDesc*} $ad$
        \Comment descriptor for child adoption task
        \State \textbf{PurgeDesc*} $pd$
        \Comment descriptor for batch deletion task
        \State \textbf{Stack*} $s,\;s_{old}$
        \Comment new and old deletion stack 
        \State $min \gets \NIL$
        \State $s_{old} \gets stack,\:s \gets \textbf{new Stack},*s \gets *s_{old}$ \label{l:readstack}
        \For {$d \gets D-1;\;d>0$} \label{l:delfor}
        \State $last \gets s.node[d],\;ad \gets last.adesc$
        \If {$ad \AND d \in [ad.dp, ad.dc)$}
        \State $\textsc{FinishInserting}(last,\;ad)$
        \EndIf
        \State $child \gets \textsc{ClearMark}(last.child[d],\;F_{adp}|F_{prg})$
        \If {$child = \NIL$}
        \State $d \gets d-1$
        \State \CONTINUE
        \EndIf
        \State $prg \gets child.prg$
        \If {$\textsc{IsMarked}(prg,\;F_{del})$} \label{l:testmark}
        \If {$\textsc{ClearMark}(prg,\;F_{del}) = \NIL$} \label{l:testprg}
        \State $s.node[d:D] \gets child,\;d \gets D-1$
        \Else \label{l:switchhead}
        \State $s.head \gets \textsc{ClearmMark}(prg,\;F_{del})$
        \State $s.node[d:D] \gets s.head,\;d \gets D-1$
        \EndIf
        \ElsIf {\textsc{CAS}($\&child.prg,\;prg,\;\textsc{SetMark}(prg,F_{del}))$} \label{l:delcas}
        \State $s.node[d:D] \gets child,\;min \gets child$ \label{l:delstackupdate}
        \State $\textsc{CAS}(\&stack,\;s_{old},\;s)$ \label{l:stackupdate}
        \If {$distance > R$} \label{l:checkpurge}
        \State $pd \gets \textbf{new PurgeDesc}$
        \State $pd.head \gets s.head,\;pd.prg \gets child$
        \If {$\textsc{CAS}(\&pdesc,\;\NIL,\;pd)$}
        \State \Call{FinishPurging}{$pd$}
        \EndIf
        \EndIf
        \State \BREAK
        \EndIf
        \EndFor
        \State \Return $min$
        \EndFunction
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}[ht]
    \caption{Batch Physically Deletion}
    \label{alg:purge}
    \begin{algorithmic}[1]
        \Function{FinishPurging}{$\textbf{PurgeDesc*}\;pd$}
        \State $\textbf{Node*}\;curr,\;child,\;hd,\;prg,\;hd_{new},\;prg_{copy}$
        \State $hd \gets pd.head,\;prg \gets pd.prg$
        \If {$hd \neq head$} \Return
        \EndIf
        \State $hd_{new} \gets \textbf{new Node},\;prg_{copy} \gets \textbf{new Node}$ 
        \State $*prg_{copy} \gets *prg,\;prg_{copy}.child[0:D] \gets \NIL$
        \State $hd_{new}.prg \gets F_{del},\;hd_{new}.seq \gets hd.seq+1$ \label{l:seqinc}
        \For {$d \gets 0,\;curr \gets hd;\;d < D$} \label{l:prgfor}
        \While{$prg.k[d] > curr.k[d]$} \label{l:findprg}
        \State $curr \gets \textsc{ClearMark}(curr.child[d], F_{adp}|F_{prg})$
        \State $ad \gets curr.adesc$ 
        \If {$ad \neq \NIL \AND d \in [ad.dp, ad.dc)$} 
        \State $\textsc{FinishInserting}(curr, ad)$ 
        \EndIf 
        \EndWhile
        \While {$!\textsc{IsMarked}(child,\;F_{adp} | F_{prg}) \AND !\textsc{CAS}$ $(\&curr.child[i],\;child,\;\textsc{SetMark}(child,\;F_{prg})$} \label{l:prgwhile}
        \State $child \gets curr.child[d]$
        \EndWhile 
        \If{$!\textsc{IsMarked}(child, F_{prg})$} \label{l:prgcheckrestart}
        \State $curr \gets hd,\;d \gets 0$ \label{l:prgrestart}
        \State \CONTINUE
        \EndIf
        \State $child \gets \textsc{ClearMark}(child, F_{prg})$
        \If {$curr = hd$}
        \State $hd_{new}.child[d] \gets child,\;prg_{copy}.child[d] \gets F_{del}$
        \Else
        \State $prg_{copy}.child[d] \gets child$
        \If {$d = 0 \OR prg_{copy}.child[d-1] = F_{del}$}
        \State $hd_{new}.child[d] \gets prg_{copy}$ 
        \EndIf
        \EndIf
        \State $d \gets d+1$
        \EndFor
        \State $\textsc{CAS}(\&hd.prg,\;F_{del},\;\textsc{SetMark}(prg,F_{del}))$
        \State $\textsc{CAS}(\&prg.prg,\;F_{del},\;\textsc{SetMark}(hd_{new},F_{del}))$
        \State $\textsc{CAS}(\&head,\;hd,\;\textsc{ClearMark}(prg.prg,\;F_{del}))$
        \State $\textsc{CAS}(\&pdesc,\;pd,\;\NIL)$
        \EndFunction
    \end{algorithmic}
\end{algorithm}


Algorithm~\ref{alg:deletemin} lists the concurrent \textsc{DeleteMin} operation, which traverses the priority queue and finds the first node that is not marked for deletion.
It starts from reading the stack ($s_{old}$) and making a local copy, $s$ (line~\algref{alg:deletemin}{l:readstack}).
The search iterates through the stack starting from the highest dimension (line~\algref{alg:deletemin}{l:delfor}) because children with smaller keys are assigned higher dimensionality according to Definition~\ref{def:mdlistsort}.
The last known minimal node ($last$) in dimension $d$ is read from the stack, and the new minimal node ($child$) must be a dimension $d$ child of $last$.
This is because we have traversed nodes with smaller keys in previous iterations.
We clear both $F_{adp}$ and $F_{prg}$ from $child$ and test if it is empty.
If so, we continue to search in lower dimensions.
We test if the node has already been logically deleted on line~\algref{alg:deletemin}{l:testmark}.
A node is considered logically deleted once its $prg$ field is marked with $F_{del}$.
If $child$ is marked, which could happen due to competing \textsc{DeleteMin} operations, we update the local stack and proceed to find the next minimal node.
The $prg$ field of a purged node points to the new head of the queue.
If $child$ is not purged as indicated by a NIL $prg$ field on line~\algref{alg:deletemin}{l:testprg}, the local stack is updated with $child$.
Otherwise, the stack is set to the new head. 
In both cases, the search starts anew from the highest dimension.
On line~\algref{alg:deletemin}{l:delcas}, we try to set the deletion flag in case $child$ is not already marked for deletion.
Upon success, we update the stack to reflect the new minimal node, and try to announce the stack globally (line~\algref{alg:deletemin}{l:stackupdate}). 
We do not need to retry posting the announcement because \textsc{DeleteMin} operations can always reach unmarked nodes from the old stack. Starting from the most recent stack helps boost the search speed. 
We determine if a physical deletion is needed (line~\algref{alg:deletemin}{l:checkpurge}) by comparing the distance of a node to the user-defined threshold $R$ (values ranging from 8 to 64 prove to perform well in our empirical study).
The distance is measured by the number of intermediate nodes between the newly marked node and the head node, which can be estimated by counting the number of logically deleted nodes traversed by the search process. 
%We give more details on choosing appropriate threshold $R$ in Section~\ref{sec:experiment}.

The physical deletion or purge is announced globally through \textsc{PurgeDesc}, and executed by calling \textsc{FinishPurging}, which is listed in Algorithm~\ref{alg:purge}. 
We read the head ($hd$) and the purged node ($prg$) from the descriptor.
The goal is to discard all nodes between $hd$ and $prg$ from the priority queue so that they are not visible to future operations.
To allow simultaneous execution of this helping function, we allocate and modify local copies of the new head ($hd_{new}$) and the purged node ($prg_{copy}$) before committing them.
The $seq$ field in the head nodes serves as a version counter that is increased every time a new head is created (line~\algref{alg:purge}{l:seqinc}).
%We need a copy of $prg$ because the purge could demote $prg$ node to a lower dimension, which is done by enabling previously invalid child slots
%Since \textsc{FinishInserting} may increase a node's dimensionality by disabling child slots, concurrent execution of these two helping function on the same node may cause inconsistency.
Starting from $hd$, the process tries to find one node in each dimension with the coordinate that is no less than that of $prg$ (line~\algref{alg:purge}{l:findprg}).
Once found, the node ($curr$) divides the list in its dimension such that its predecessors will be purged and its successors will be kept.
During the search, the pending child adoption is helped if necessary (line 12 and 13).
The next step is to transfer the dimension $d$ child of $curr$ to either $hd_{new}$ or $prg_{copy}$.
To safeguard the child, we employ the same pointer marking technique as the child adoption process except using a different flag $F_{prg}$ (line~\algref{alg:purge}{l:prgwhile}).
If the child has been adopted (line~\algref{alg:purge}{l:prgcheckrestart}), the search process needs to start over again from $hd$ (line~\algref{alg:purge}{l:prgcheckrestart}).
The child is transferred to the new head if it is a child of the old head.
Otherwise it is transferred to $prg_{copy}$.
The $prg$ field of $hd$ and $prg$ is updated allowing \textsc{DeleteMin} to reach the new head (line~\algref{alg:deletemin}{l:switchhead}).
Finally, the new head is updated and the descriptor is cleared.

\begin{algorithm}[t]
    \caption{Rewind Deletion Stack}
    \label{alg:rewind}
    \begin{algorithmic}[1]
        \Inline{RewindStack}{}
        \State $\textbf{Stack*}\;s_{new} \gets stack$
        \State $\textbf{Node*}\;prg$
        \Repeat
        \If{$s.head.seq = s_{new}.head.seq$} \label{l:samehead}
        \If{$node.key \le s_{new}.node[D-1].key$}
        \State $s.node[dp:D] \gets pred$ \label{l:rewindpred}
        \ElsIf {$first time$} $*s \gets *s_{new}$ \label{l:asitwas}
        \Else ~\BREAK \label{l:norewind1}
        \EndIf
        \ElsIf {$s_{new}.head.seq > s.head.seq$} \label{l:newerhead}
        \State $prg \gets \textsc{ClearMark}(s.head.prg)$
        \If {$prg.key \le node.key$}
        \State $s.head \gets \textsc{ClearMark}(prg.prg, F_{del})$
        \State $s.node[0:D] \gets s.head$
        \Else ~$s.node[dp:D] \gets pred$
        \EndIf
        \Else
        \State $prg \gets \textsc{ClearMark}(s_{new}.head.prg)$
        \If {$ prg.key \le s_{new}.node[D-1].key$}
        \State $s.head \gets \textsc{ClearMark}(prg.prg, F_{del})$ \label{l:rewindnewhead}
        \State $s.node[0:D] \gets s.head$
        \ElsIf {$first time$} $*s \gets *s_{new}$
        \Else ~\BREAK \label{l:norewind2}
        \EndIf
        \EndIf
        \Until {$\textsc{CAS}(\&stack,\;s_{new},\;s) \OR \textsc{IsMarked}(node.prg,$ $F_{del})$} \label{l:rewindcas}
        \EndInline
    \end{algorithmic}
\end{algorithm}


\subsection{Synchronizing Insert with DeleteMin}
\label{sec:cpqueuerewind}
In our implementation, \textsc{Insert} and \textsc{DeleteMin} are synchronized through the stack rewind mechanism.
Intuitively, a deletion thread moves the deletion stack ``forward'' while an insertion thread ``rewinds'' the stack when it detects that the stack points to a position beyond the new node. 
The insertion rewinds the stack to a position before the newly inserted node so that it is made visible to future deletion threads. 
This allows insertion threads to proceed optimistically without blocking deletion threads until the new nodes are in place. 

The \textsc{RewindStack} function listed in Algorithm~\ref{alg:rewind} consists of a CAS-based loop that reads the deletion stack and determines the rewind position.
An insertion records the head node in its local stack on line~\algref{alg:insert}{l:recordhead}.
Based on the version (determined by the $seq$ field) of the head node from the new stack, the rewind falls into three scenarios.
In the first case, the head node is still the same (line~\algref{alg:rewind}{l:samehead}).
If the last node that has been deleted has a key larger than the new node, we need to rewind the stack to the new node's predecessor (line~\algref{alg:rewind}{l:rewindpred}).
Otherwise, deletion threads have yet to reach the new node and we can skip the rewind except for the first iteration.
In that case we try to update the stack with a new object with the same contents in order to make sure the stack will not be overwritten by other threads (line~\algref{alg:rewind}{l:asitwas}).
In the second case, the head from the new stack is newer than the head from the local stack (line~\algref{alg:rewind}{l:newerhead}), which means the head of the queue where the insertion took place has been purged.  
Under such circumstances, the $prg$ field of the old head should contain a pointer to the purged node.
If the key of the purged node is no greater than the key of the new node, we have to rewind the stack as far as the new head of last purge.
Otherwise, we rewind the stack to the predecessor of the new node as we did in the first case.
In the third case, the head from the new stack is older than the head from the local stack. Here, we only need to rewind the stack to the new head node to ensure the new node is reachable (line~\algref{alg:rewind}{l:rewindnewhead}).


\section{Correctness}
\label{sec:correctness}
In this section, we sketch a proof of the main correctness property of the presented priority queue algorithm, which is quiescent consistency. Additionally, we discuss how stricter correctness conditions such as linearizability can be guaranteed through the use of time-stamps.
We explain the relaxation of the \textsc{DeleteMin} operation when the concurrent object is executed without quiescent periods. 
We begin by defining the \emph{abstract state} of a sequential priority queue and then show how to map the internal state of our concrete priority queue object to the abstract state.
We denote the abstract state of a sequential priority queue to be a set $P$.
Equation~\ref{eq:insert} specifies that an \textsc{Insert} operation grows the set if the key being inserted does not exist.
Equation~\ref{eq:delete1} and~\ref{eq:delete2} specify that a \textsc{DeleteMin} operation shrinks a non-empty set by removing the key-value pair with the smallest key.

\begin{equation} \label{eq:insert}
    \textsc{Insert}(\langle k,v \rangle)= \begin{cases}
        P \cup \{\langle k,v\rangle\} & \forall \langle k',v'\rangle \in P\;,\;k' \neq k\\
        P & \exists \langle k',v' \rangle \in P : k'=k
    \end{cases}
\end{equation}

\begin{gather}
    \label{eq:delete1}
    \textsc{DeleteMin}()= \begin{cases}
        P \setminus {\langle k,v \rangle} & P\neq\emptyset\\
        \emptyset & P=\emptyset
    \end{cases}
    \\
    \label{eq:delete2}
    \text{where } \forall \langle k',v' \rangle \in P,\;k' \neq k \implies k' > k
\end{gather}

\subsection{Invariants}
Now we consider the concurrent priority queue object. 
By a \emph{node}, we refer to an object of type \textbf{Node} that has been allocated and successfully linked to an existing node (line~\algref{alg:insert}{l:link}). 
We denote the $head$ node with $seq=i$ by $head_i$, and the set of nodes that are reachable from $head_i$ by $L_i$. 
At any point of time, the set of all nodes can be denoted by $L=\bigcup_{i=0}^{m}L_i$ where $m = head.seq$.
The following invariants are satisfied by the concrete priority queue object at all times. 
Invariant~\ref{inv:adpflag} states that if a node has no pending child adoption task, its dimension $d$ child must have $d$ invalid child slots leaving $D-d$ valid ones.

\begin{invariant} \label{inv:adpflag}
$\forall n,n' \in L,\textsc{ClearMark}(n.child[d],F_{adp}|F_{prg}) \linebreak=n'\;\land\;n.adesc=\NIL \implies \forall i \in [0,d), \textsc{IsMarked}(n'.child$ $[i],F_{adp})=\TRUE$
\end{invariant}
\begin{proof}
    By observing the statements at line~\algref{alg:insert}{l:initadp} and~\algref{alg:adoption}{l:setadp} we see that the $F_{adp}$ flags are properly initialized before linking a new node to its predecessor and updated properly whenever a child is adopted.
\end{proof}

\begin{invariant} \label{inv:reachability}
    $\forall n \in L_i, \exists p=\{d_0,d_1,...,d_m\} : d_0\le d_1 \le ... \le d_m\;\land\;head_i.child[d_0].child[d_1]...child.[d_m]=n$
\end{invariant}
\begin{proof}
    Initially, the invariant holds because any new node can be reached from $head_i$ following the path given by \textsc{LocatePred}.
    The path may be altered by subsequent insertions. 
    Since we do not unlink nodes from the data structure, the claim follows by noting that an insertion adds a new node either between two contiguous nodes or as a leaf node. 
Future insertions either replace a node in $p$ or add a new node.
%If $dp = dc$, add new link, if $dp < dc if dp < d_1 < dc d_1$ is adopted,link replace, if $d_1 > dc$, add new link. 
\end{proof}

%\begin{lemma} \label{lmm:adoption}
    %Child adoption appears transparent to traversing operations
%\end{lemma}
%\begin{proof}
    %adesc is set once, and will be cleared after first execution.
%All access to child slots are guarded by FinishInserting, forcing child adoption ensuring consistency.
    %Finishing the adesc before accessing nodes with adesc set 
%\end{proof}

%\begin{lemma}
    %At any time, nodes in $L_i$ form an MDList that complies with Definition~\ref{def:mdlist}.
%\end{lemma}
%\begin{proof}
%Invariant~\ref{inv:adpflag} shows that for any node n with dimension d, only children with d or above dimension is accessible, thus the dimension of a node is always smaller or equal to the dimensions of its children.
%\end{proof}

%\begin{lemma}
%LocatePred always find earlies insertion position, never overshoot even when child slot is invalidated
%Because a unique path exist if a node is in the set
%So if a node is in the set, LocatePred will be able to reach it and dc = D, this guarantees that no duplicate keys will be inserted.
%\end{lemma}
%\begin{proof}
    %Follow Invariant~\ref{inv:link}, and above lemma. 
    %A node in th set can be reached through a serial of child[i] pointers where i is increasing
    %define the sequence of pointers as unique search path
%\end{proof}

%\begin{lemma}
%If a node is live, the traversing mechanism of deletemin will be able to reach it
%\end{lemma}

We now show that the nodes without a deletion mark and accessible through the deletion stack form a strictly well-ordered set that is equivalent to $P$.
Invariant~\ref{inv:order} states that the ordering property described by Definition~\ref{def:mdlistsort} is kept at all times.

\begin{invariant} \label{inv:order}
    $\forall n,n' \in L, n.child[d]=n' \implies n.key < n'.key$ $\land\;\forall i \in [0, d)\; n.k[i] = n'.k[i] \land n.k[d]<n'.k[d]$
\end{invariant}
\begin{proof}
    Initially the invariants trivially holds.
    The linkage among nodes is only changed by insertion, child adoption and purge.
    Insert preserves the invariants because the condition checks on line~\algref{alg:insert}{l:predcheck1} and~\algref{alg:insert}{l:predcheck2} guarantee that $\forall i \in [0, dp)\; pred.k[i] = node.k[i] \land pred.k[dp]<node.k[dp]$.
    Child adoption preserves the invariant because $\forall i \in [dp, dc)\; node.k[i] = curr.k[i] < curr.child[i].k[i]$.
    Similarly, purge preserves the ordering property because of the condition check on line~\algref{alg:purge}{l:findprg}.
%A node's dimensionality only increases, never decreases.
%Note invariant $dc \ge dp$
\end{proof}

\begin{invariant} \label{inv:stackorder}
    $\forall d_1,d_2 \in [0,D), d_1<d_2 \implies \forall i \in [0,d_1],\linebreak stack.node[d_1].k[i]=stack.node[d_2].k[i] \land stack.node[d_1].$ $k[d_2] < stack.node[d_2].k[d_2]$
\end{invariant}
\begin{proof}
    Initially, the stack contains a dummy head node and the invariant holds.
    \textsc{DeleteMin} sets the value of the stack's nodes in the range of $[d,D)$ to $child$ (line~\algref{alg:deletemin}{l:delstackupdate}).
    Following Invariant~\ref{inv:order}, $child$ has a larger key than $s.node[d]$.
    \textsc{Insert} updates the stack with the path recorded in \textsc{LocatedPred}, according to Invariant~\ref{inv:reachability} and~\ref{inv:order} the path contains nodes with increasing keys.
\end{proof}

\begin{invariant}\label{inv:stacksplit}
    $\forall d \in [0,D), stack.node[d].child[d].key > stack.node[D-1].key$
\end{invariant}
\begin{proof}
    Following Invariant~\ref{inv:order}, $stack.node[d].child[d].k[d] > stack.node[d].k[d]$.
    Following Invariant~\ref{inv:stackorder}, $stack.node[D-1].k[d] = stack.node[d].k[d]$.
\end{proof}

In summary, Invariant~\ref{inv:stacksplit} states that the deletion stack splits the nodes in $L_i$ into two groups: those that are reachable by the \textsc{DeleteMin} algorithm and those that are not.
We define the latter by $M_i=\{n|n\in L_i \land n.key \leq stack.node[D-1].key\}$, and $M=\bigcup_{i=0}^{m}M_i$.
We also define the set of logically deleted nodes by $S=\{n|n\in L \land \textsc{IsMarked}(n.prg, F_{del}) = \TRUE\}$.
The abstract state can then be defined as $P \equiv L \setminus M \setminus S$.

\subsection{Quiescent Consistency and Linearizability}
We now sketch a proof that our algorithm is a quiescently consistent priority queue implementation that complies with the abstract semantics. Quiescent consistency states that method calls separated by a period of quiescence should appear to take effect according to their real time order~\cite{herlihy2012art}.

\begin{theorem}
    A successful $\textsc{Insert}(\langle k,v\rangle)$ operation that does not overlap with any \textsc{FinishPurging}, i.e. following a period of quiescence, takes effect atomically at one statement.
\end{theorem}
\begin{proof}
    If an \textsc{Insert} operation returns on line~\algref{alg:rewind}{l:norewind1},~\algref{alg:rewind}{l:norewind2}, or the second condition on line~\algref{alg:rewind}{l:rewindcas}, the deletion stack is not updated.
    The decision point for such an operation to take effect is when the CAS operation on line~\algref{alg:insert}{l:link} succeeds.
    The remaining CAS operations in the child adoption process will eventually succeed according to Lemma~\ref{lmm:finitestep}.
    If an \textsc{Insert} operation needs to rewind the deletion stack, i.e. $\langle k,v \rangle \in M \implies \langle k,v \rangle \notin P$, the decision point for it to take effect is when the CAS operation on line~\algref{alg:rewind}{l:rewindcas} succeeds.
    The newly updated deletion stack ensures that $stack.node[D-1].key \le key$, thus renders the new node reachable for \textsc{DeleteMin} operations, i.e. $M = M \setminus \{\langle k,v \rangle,...\}$.
    Equation~\ref{eq:insert} holds in both cases because $L=L\cup \langle k,v \rangle \land \langle k,v \rangle \notin M$.
\end{proof}

\begin{theorem}
    A \textsc{DeleteMin} that does not overlap with any \textsc{Insert} operation takes effect atomically at one statement.
\end{theorem}
\begin{proof}
    A \textsc{DeleteMin} operation updates the abstract state by growing $S$.
    The decision point for it to take effect is when the CAS operation on line~\algref{alg:deletemin}{l:delcas} successfully marks a node for deletion, or on line~\algref{alg:deletemin}{l:delfor} when it reaches the last node in the deletion stack without finding an unmarked node.
    In the first case, Equations~\ref{eq:delete1} and~\ref{eq:delete2} hold because $S' = S \cup \langle k,v \rangle \implies P' = P \setminus \{\langle k,v \rangle$\}.
    In the second case, $P' = P = \emptyset$.
\end{proof}

In our algorithm, the \textsc{Insert} operation is linearizable with respect to other concurrent \textsc{Insert} operations, and the \textsc{DeleteMin} operation is linearizable with respect to other \textsc{DeleteMin} operations.
However, the \textsc{DeleteMin} operation is not linearizable with the overlapping \textsc{Insert} operations because only those nodes $\{n|n \notin M_i\}$ are reachable from $stack_i$ .
At the beginning of the \textsc{DeleteMin} operation, the deletion stack is read once on line~\algref{alg:deletemin}{l:readstack}. 
The subsequent traversal will not be aware of any unmarked nodes removed from $M$.
One method of designing a linearizable algorithm is the time-stamping mechanism adopted by Shavit and Lotan in~\cite{shavit2000skiplist}, in which each deletion thread returns the minimal undeleted node among those inserted completely before it reads the deletion stack.
After a node is inserted on line~\algref{alg:insert}{l:link}, it acquires a time-stamp.
A deletion thread notes the time at which it reads the stack and only processes nodes with a smaller time-stamp.  
This time-stamping mechanism ensures that the \textsc{DeleteMin} operations see a consistent abstract state throughout the search process.

\subsection{Relaxation}
Our algorithm is relaxed in the sense that it is quiescently consistent.
We prefer quiescent consistency over linearizability because it allows for higher level of concurrency.
The trade-off is that in concurrent executions without any quiescence the order in which method calls take effect may be undefined.
Now we consider the execution of the \textsc{FinishPurging} function.

\begin{lemma}
    Purge does not change the abstract state $P$.
\end{lemma}
\begin{proof}
    Note that in Algorithm~\ref{alg:purge}, $L$ does not change because no new node is inserted; $M$ does not change because the deletion stack is not modified; $S$ does not change because no deletion flag is marked.
\end{proof}

\begin{theorem} \label{th:bound}
    Let $key_{prg}$ denote the key of the last $prg$ node in Algorithm~\ref{alg:purge}.
    Without quiescence, a successful \textsc{DeleteMin} operation either returns $n \in P : \forall n' \in P,\;n.key < n'.key$ or $n \in P : n.key < key_{prg}$.
\end{theorem}
\begin{proof}
    The purge algorithm creates a new head node while keeping the old head, thus the ordering relation between two set of nodes $Q=\{n|n\in L_i \land n.key \le key_{prg}\}$ and $Q'=\{n'|n' \in L_{i+1} \land n'.key \le key_{prg}\}$ is not defined.
The relaxation takes place when \textsc{Insert} operations overlap with \textsc{FinishPurge} because new nodes can be inserted into either set depending on when the insertion starts.
If there are quiescent periods between insertions and purges, all new nodes are inserted into $Q'$, which implies $Q \subseteq S$.
Otherwise, $\exists n\in Q, n' \in Q' : n \notin S \land n' \notin S \land n.key > n'.key$.
When the \textsc{DeleteMin} operation switches to the new head on line~\algref{alg:deletemin}{l:switchhead} the strict ordering property is temporarily relaxed.
\end{proof}

We define the bound of the relaxation by the number of minimal nodes that might be skipped by \textsc{DeleteMin} operations.
According to Theorem~\ref{th:bound}, the exact upper bound of the relaxation is generally undetermined because it depends on the key of the last purged nodes. 
However, if the distribution of keys is known beforehand, we could set the purge threshold based on a fixed key, which in turn gives a fixed upper bound.

\begin{figure*}[t]
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/amd100insertion.pdf}
        \caption{100\% \textsc{Insert} on the NUMA System}
        \label{fig:100ins}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/amd0insertion.pdf}
        \caption{100\% \textsc{DeleteMin} on the NUMA System}
        \label{fig:0ins}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/amd50insertion.pdf}
        \caption{50\% \textsc{Insert} on the NUMA System}
        \label{fig:50ins}
    \end{subfigure}
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/intel50insertion.pdf}
        \caption{50\% \textsc{Insert} on the SMP System}
        \label{fig:50insintel}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/intel80insertion.pdf}
        \caption{80\% \textsc{Insert} on the SMP System}
        \label{fig:80ins}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.33\textwidth}
        \centering
        \includegraphics[width=1\columnwidth]{./data/amdsweep75insert.pdf}
        \caption{Dimensionality and Performance}
        \label{fig:sweep}
    \end{subfigure}
    \caption{Throughput of the Priority Queues (MDPQs are named by their dimensionality, e.g. 8DPQ is an MDPQ with 8 dimensions)}
    \label{fig:throughput}
\end{figure*}

\subsection{Lock Freedom}
Our algorithm is lock-free because it guarantee that for every possibly execution scenario, at least one thread makes progress.
We prove this by examining unbounded loops in all possible execution paths, which can delay the termination of the operations.
\begin{lemma} \label{lmm:finitestep}
    \textsc{FinishInserting} (Algorithm~\ref{alg:adoption}) and \textsc{FinishPurging} (Algorithm~\ref{alg:purge}) complete in finite steps.
\end{lemma}
\begin{proof}
    We observe that the \texttt{repeat} loops on line~\algref{alg:adoption}{l:adoptionwhile} and~\algref{alg:purge}{l:prgwhile} are subject to fail and retry when another insertion thread concurrently updates $curr.child[i]$.
    The number of retries is bounded by $\sqrt[D]{N}$, which is the maximum number of nodes in each dimension.
    For \textsc{FinishPurging}, the \texttt{for} loop (line~\algref{alg:purge}{l:prgfor}) is also unbounded.
    According to Invariant~\ref{inv:reachability}, the purged node can always be reached from the head through a sequence of child pointers and the number of reties is bounded by $D \sqrt[D]{N}$.
\end{proof}

\begin{theorem}
    \textsc{Insert} and \textsc{DeleteMin} operations are lock-free.
\end{theorem}
\begin{proof}
    Note that all shared variables are concurrently modified by CAS operations, and the CAS-based unbounded loops (line~\algref{alg:insert}{l:link}, ~\algref{alg:deletemin}{l:delcas}, and ~\algref{alg:rewind}{l:rewindcas}), only retry when a CAS operation fails.
    This means that for any subsequent retry, there must be one CAS that succeeded, which caused the termination of the loop.
    All reads of child pointer are preceded by \textsc{FinishInserting}, which completes child adoption in finite steps to ensure consistency.
    Furthermore, our implementation does not contain cyclic dependencies between CAS-based loops, which means that the corresponding operation will progress.
\end{proof}

\section{Experimental Evaluation}
\label{sec:experiment}

We compare the performance of our algorithm (MDPQ) against Intel TBB's concurrent priority (TBBPQ)~\cite{reinders2007intel}, Linden and Jonsson's linearizable priority queue (LJPQ)~\cite{linden2013skiplist}, and Herlihy and Shavit's quiescently consistent priority queue (HSPQ)~\cite{herlihy2012art}.
Intel TBB is an established industry standard concurrent library.
TBBPQ is based on an array-based heap and employs a dedicated aggregator thread to perform all operations.
It is not lock-free because a halting aggreagator thread prevents system wide progress.
LJPQ is the best available linearizable priority queue that minimizes contention on the head node.
HSPQ shares the same correctness guarantee as our algorithm.
Both LJPQ and HSPQ are built on top of Fraser's~\cite{fraser2004practical} state of the art lock-free skiplist implementation.
The MDPQ implementation did not reclaim memory from purged node, but hazard pointer~\cite{michael2004hazard} and reference counting~\cite{gidenstam2009efficient} techniques can be applied to ensure safe reclamation of memory.
%You are right that purged node could be accessed after RewindStack. Garbage collection can resolve this issue and we have added clarification to the revision.
We employ a micro-benchmark to evaluate the performance of these approaches for uniformly distributed keys.
This canonical evaluation method~\cite{harris2001pragmatic,shavit2000skiplist,linden2013skiplist,sundell2005fast} consists of a tight loop that randomly chooses to perform either an \textsc{Insert} or a \textsc{DeleteMin} operation. 
Each thread performs one million operations and we take the average from three runs.
The tests are conducted on a 64-core NUMA system (4 AMD opteron CPUs with 16 cores per chip @2.1 GHz) and a 12-core SMP system (1 Intel Xeon 6-core CPU with hyper-threading @2.9GHz). 
Both the micro-benchmark and the priority queue implementations are compiled with GCC 4.7 with level three optimizations.
%TODO: we fix affinity

Figures~\ref{fig:100ins},~\ref{fig:0ins} and~\ref{fig:50ins} illustrate the throughput of the algorithms on the NUMA system.
The $y$-axis represents the throughput measured by \emph{operation per second}, and the $x$-axis represents the number of threads.
Both axes are in logarithmic scale.
In Figure~\ref{fig:100ins}, threads perform solely \textsc{Insert} operations.
We observe that the skiplist-based and MDList-based approaches explore fine-grained parallelism and exhibit similar scalability trends.
The throughput increases linearly until 16 threads, and continues to increase at a slower pace until 64 threads.
Because executions beyond 16 threads span across multiple chips, the performance growth is slightly reduced due to the cost of remote memory accesses.
The executions are no longer fully concurrent beyond 64 threads, thus the overall throughput is capped and may even reduce due to context switching overhead.
The performance of LJPQ are on par with HSPQ because they employs identical skiplist insertion algorithms.
Our priority queue based on an 8DList (8DPQ) achieves a $26\%$ speedup over LJPQ on 16 threads and a further $55\%$ speedup on 64 threads.
Each insertion in MDPQ modifies at most two consecutive nodes, incurring less remote memory access than skiplist-based approaches.
When we increase the dimensionality of MDPQ to 16, we obtain on average a $50\%$ throughput gain over 8DPQ.
A 16DPQ contains at most 4 nodes in each dimension.
In order to reach the target position the search operation traverses a maximum of 64 nodes comparing to 128 nodes in a 8DPQ.
Further increases in dimensionality can result in diminishing returns for concurrent \textsc{Insert}.
The growing number of child pointers causes synchronization overhead that cancels the benefit of having less nodes in each dimension.
TBBPQ, on the other hand, exhibits reduced throughput when increasing the number of threads.
Its heap-based structure achieves high throughput on a single thread, but the aggregator effectively serializes all operations and limits the throughput in concurrent executions.

Figure~\ref{fig:0ins} shows the results for \textsc{DeleteMin} operations.
We fill the data structures with one million elements and measure the time it takes to dequeue them.
The overall throughput decreases as the number of threads increases, which matches the observation that \textsc{DeleteMin} is the sequential bottleneck of a priority queue algorithm.
Throughput of HSPQ drops significantly because it initiates physical deletion for every logically deleted node.
The physical deletion constantly swings pointers which causes heavy content on the head node.
8DPQ and LJPQ achieve comparable performance because they both employ batch physical deletion, which reduces the total number of pointer updates.
4DPQ outperforms LJPQ by $50\%$ starting from 16 threads because the number of pointers, which the deletion needs to update, reduces as dimensionality decreases.
TBBPQ is able to keep a constant throughput starting from 4 threads.
As the \textsc{DeleteMin} operation is intrinsically sequential, having a dedicated aggregator helps relieve contention by allowing other threads to wait while a single thread performs the update.
%However, since it does not explore fine-grained parallelism, its throughput is still below average.

We show the results where threads randomly choose operations with a distribution of 50\% \textsc{Insert} and 50\% \textsc{DeleteMin} in Figure~\ref{fig:50ins}.
As the level of concurrency increases, the overall throughput peaks at some point where the executions strike a balance between the increasing throughput of \textsc{Insert} and the decreasing throughput of \textsc{DeleteMin}.
8DPQ exhibits the best overall throughput, outperforming LJPQ by $50\%$ on average.
Our algorithm allows insertion of new nodes into a position before a logically deleted node.
The concurrent executions of \textsc{Insert} and \textsc{DeleteMin} guarantees quiescent consistency, which is relaxed compared to linearizability.
This helps improve throughput over Linden's logical deletion scheme where deletion threads cannot proceed past an ongoing insertion~\cite{linden2013skiplist}.
4DPQ achieves about $10\%$ speedup over 8DPQ on 64 and 128 threads at the price of being slower when the number of threads is low. 

Figure~\ref{fig:50insintel} and~\ref{fig:80ins} show the throughput of the algorithms on the SMP system.
The $x$-axis in these graphs is in linear scale.
In Figure~\ref{fig:50insintel}, the test operations consist of an equal amount of \textsc{Insert} and \textsc{DeleteMin} operations.
8DPQ and LJPQ perform equally well, obtaining $30\%$ speedup over TBBPQ and $50\%$ over HSPQ with 12 threads.
Executions beyond 12 threads are preemptive, and the overhead of context switching leads to a reduction of 8DPQ and LJPQ's throughput.
In Figure~\ref{fig:80ins}, we increase the ratio of \textsc{Insert} operations to $80\%$.
This is to simulate the typical access pattern of best-first search algorithms, in which a worker thread insert multiple new nodes (search state) upon dequeuing the node with highest priority~\cite{burns2010best}.
In this case, all approaches except TBBPQ exhibit identical scalability trends.
16DPQ obtains $7\%$ more throughput than HSPQ on 12 threads.
TBBPQ obtains the same amount of throughput in both cases.
Its compact heap structure is specifically optimized for Intel chips, which provides larger cache than the AMD CPU.
%The SMP system contains a single Intel CPU, which has a shorter memory latency than the AMD system.

In Figure~\ref{fig:sweep}, we sweep the dimension of MDPQ from 4 to 32 on the NUMA system, and show that the algorithm achieves maximum throughput with 12 dimensions on 16 threads. 
On all scale levels, we see that the throughput converges towards 12 dimensions.
This means that the way the dimensionality of an MDPQ affects its performance is independent from the number of threads.
The performance of MDPQ can be optimized if the access pattern of the user application is taken into account.
The parametric sweep also reveals that the overall throughput is capped with 16 threads.
This implies that the algorithms with inherent sequential semantics, such the \textsc{DeleteMin} operation, pose scalability challenges for NUMA systems.

Overall, MDPQ excels at high levels of concurrency.
The locality of its operations makes it suitable for NUMA architectures where remote memory access incurs considerable performance penalties.
On an SMP system with low concurrency, MDPQ performs equally well and sometimes slightly better than the state of the art skiplist-based approaches.

\section{Conclusion}
\label{sec:conclusion}
In this paper, we introduced a lock-free priority queue design based on a novel multi-dimensional list.
We exploited spatial locality to increase the throughput of the \textsc{Insert} operation, and adopted quiescent consistency to address the sequential bottleneck of the \textsc{DeleteMin} operation.
When compared to the best available skiplist-based and heap-based algorithms, our algorithm achieved performance gains in all scenarios and an average of $50\%$ performance improvement on a 64-core multiprocessor system.
The proposed MDList guarantees logarithmic worst-case search time by mapping keys into high dimensional coordinates.
The performance of an MDList-based data structure can be tailored to different access patterns by changing its dimensionality.
Furthermore, an MDList provides a scalable alternative to skiplists and search trees, which opens up opportunities for implementing other multiprocessor data structures, such as dictionaries and sparse vectors. 

\bibliographystyle{abbrv}
\bibliography{citation}

\end{document}
